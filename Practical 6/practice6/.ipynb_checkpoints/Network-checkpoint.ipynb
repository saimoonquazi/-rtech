{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Hello again. In this exercise we are going to\n",
    "1. use pre-trained model for classification,\n",
    "2. calculate saliency of the image - what regions the classification decision is most sensitive to,\n",
    "3. create fooling images (called adversarial examples) for neural networks.\n",
    "\n",
    "We are going to use ResNet-50 model included with Keras. For more information about the model see [this paper](https://arxiv.org/abs/1512.03385)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using pre-trained model\n",
    "\n",
    "Keras makes it really easy to make use of pretrained models. For list of currently supported image classification models see [Keras documentation](https://keras.io/applications/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.1:** What is the number of parameters? What is the number of weight layers? Where ResNet gets its name?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the image that we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = image.load_img('elephant.jpg', target_size=(224, 224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert image to array\n",
    "x = image.img_to_array(img)\n",
    "# add batch axis\n",
    "x = x[np.newaxis] \n",
    "# subtract mean from the image\n",
    "x = preprocess_input(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the image through the network and read out the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict(x)\n",
    "decode_predictions(probs, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the label and name of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import CLASS_INDEX\n",
    "\n",
    "def label2str(label):\n",
    "    return CLASS_INDEX[str(label)][1]\n",
    "\n",
    "label = np.argmax(probs)\n",
    "print(label, label2str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency maps\n",
    "\n",
    "For saliency maps we need to calculate gradient of the input image with respect to the class probability (or score). Basically this tells us, which part of the image the model is most sensitive to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produces computational graph for calculating gradients of correct class probability w.r.t. input image\n",
    "grads = K.gradients(model.output[0, label], model.input)\n",
    "# creates a wrapper around computational graph, so that we can use it as a function\n",
    "grads_saliency = K.function([model.input, K.learning_phase()], grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the second parameter in list is 1 for training phase, 0 for test phase\n",
    "x_grads = grads_saliency([x, 0])[0]\n",
    "x_grads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.2:** which layers behave differently in train/test phase?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.3:** we are interested in sensitivity to pixel locations, ignoring the sign and color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Take absolute values of the gradients and maximum over channels.     #\n",
    "##############################################################################\n",
    "x_saliency = None\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "assert x_saliency.shape == x.shape[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function for denormalizing images\n",
    "x_mean = np.array([103.939, 116.779, 123.68])\n",
    "def decode_image(x):\n",
    "    return np.clip((x + x_mean)[..., ::-1], 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(decode_image(x[0]))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(x_saliency[0], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.4:** what parts of the image is the classifier sensitive to?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fooling the network\n",
    "\n",
    "Now we are going to create a picture that looks very much like an elephant, but the network classifies it as something completely irrelevant. Being easily fooled is well known problem of neural networks and is active area of research. For more information and references see [this blog post](https://blog.openai.com/adversarial-example-research/).\n",
    "\n",
    "For this we are going to calculate the gradients of target class probablity w.r.t. the input image and perform gradient ascent, i.e. change the picture so that the target class has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fun we choose paper towel :)\n",
    "target = 700\n",
    "print(target, label2str(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradients of target class w.r.t. the input image\n",
    "grads = K.gradients(model.output[0, target], model.input)\n",
    "# inputs are image and learning phase, outputs are probabilities and gradients\n",
    "grads_fool = K.function([model.input, K.learning_phase()], [model.output] + grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.5:** Implement gradient ascent to change the input image so that the target class probability increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 10\n",
    "x_fake = x.copy()\n",
    "for i in range(100):\n",
    "    preds, x_grads = grads_fool([x_fake, 0])\n",
    "\n",
    "    new_label = np.argmax(preds)\n",
    "\n",
    "    print(i, ':', \"current class:\", label2str(new_label), \"(%.02f)\" % preds[0, new_label], \"target class:\", label2str(target), \"(%.02f)\" % preds[0, target])\n",
    "    if new_label == target:\n",
    "        break\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO: Implement gradient ascent to change the input image so that the      #\n",
    "    #       target class probability increases. NB! You should normalize the     #\n",
    "    #       gradients using L2 norm before multiplying them with learning rate   #\n",
    "    #       and adding to the input image.                                       #\n",
    "    ##############################################################################\n",
    "    x_fake += None\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(decode_image(x[0]))\n",
    "plt.title(label2str(label))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(decode_image(x_fake[0]))\n",
    "plt.title(label2str(target))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(decode_image((x - x_fake)[0]))\n",
    "plt.title(\"differences\")\n",
    "plt.axis('off')\n",
    "\n",
    "# it's hard to even see the diffferences, so let's amplify them\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(decode_image((x - x_fake)[0] * 10))\n",
    "plt.title(\"differences x10\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.6:** what are the potential implications of adversarial examples?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow_p36]",
   "language": "python",
   "name": "Python [tensorflow_p36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
